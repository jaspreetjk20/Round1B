{
  "analysis_metadata": {
    "persona": "PhD Researcher in Computational Biology",
    "job_to_be_done": "Prepare a comprehensive literature review focusing on methodologies, datasets, and performance benchmarks",
    "input_documents": [
      "1B.pdf"
    ],
    "timestamp": "2025-07-27 12:45:53",
    "total_sections": 5
  },
  "ranked_sections": [
    {
      "document": "1B",
      "section_title": "Manymethodsof",
      "page_number": 8,
      "content": "4.3 Learning Hierarchical Representations Through Deep SL, UL, RL Many methods of Good Old-Fashioned Artiﬁcial Intelligence (GOFAI) (Nilsson, 1980) as well as more recent approaches to AI (Russell et al., 1995) and Machine Learning (Mitchell, 1997) learn hierarchies of more and more abstract data representations. For example, certain methods of syn- tactic pattern recognition (Fu, 1977) such as grammar induction discover hierarchies of formal rules to model observations. The partially (un)supervised Automated Mathematician / EURISKO (Lenat, 1983; Lenat and Brown, 1984) continually learns concepts by combining previously learnt concepts. Such hierarchical representation learning (Ring, 1994; Bengio et al., 2013; Deng and Yu, 2014) is also a recurring theme of DL NNs for SL (Sec. 5), UL-aided SL (Sec. 5.7, 5.10, 5.15), and hierarchical RL (Sec. 6.5). Often, abstract hierarchical representations are natural by-products of data compression (Sec. 4.4), e.g., Sec. 5.10. 4.4 Occam’s Razor: Compression and Minimum Description Length (MDL) Occam’s razor favors simple solutions over complex ones. Given some programming language, the principle of Minimum Description Length (MDL) can be used to measure the complexity of a so- lution candidate by the length of the shortest program that computes it (e.g., Solomonoff, 1964; Kolmogorov, 1965b; Chaitin, 1966; Wallace and Boulton, 1968; Levin, 1973a; Solomonoff, 1978; Rissanen, 1986; Blumer et al., 1987; Li and Vit´anyi, 1997; Gr¨unwald et al., 2005). Some methods explicitly take into account program runtime (Allender, 1992; Watanabe, 1992; Schmidhuber, 1997, 2002); many consider only programs with constant runtime, written in non-universal programming languages (e.g., Rissanen, 1986; Hinton and van Camp, 1993). In the NN case, the MDL princi- ple suggests that low NN weight complexity corresponds to high NN probability in the Bayesian view (e.g., MacKay, 1992; Buntine and Weigend, 1991; Neal, 1995; De Freitas, 2003), and to high generalization performance (e.g., Baum and Haussler, 1989), without overﬁtting the training data. Many methods have been proposed for regularizing NNs, that is, searching for solution-computing but simple, low-complexity SL NNs (Sec. 5.6.3) and RL NNs (Sec. 6.7). This is closely related to certain UL methods (Sec. 4.2, 5.6.4). 4.5 Fast Graphics Processing Units (GPUs) for DL in NNs While the previous millennium saw several attempts at creating fast NN-speciﬁc hardware (e.g., Jackel et al., 1990; Faggin, 1992; Ramacher et al., 1993; Widrow et al., 1994; Heemskerk, 1995; Korkin et al., 1997; Urlbe, 1999), and at exploiting standard hardware (e.g., Anguita et al., 1994; Muller et al., 1995; Anguita and Gomes, 1996), the new millennium brought a DL breakthrough in form of cheap, multi- processor graphics cards or GPUs. GPUs are widely used for video games, a huge and competitive market that has driven down hardware prices. GPUs excel at the fast matrix and vector multiplications required not only for convincing virtual realities but also for NN training, where they can speed up learning by a factor of 50 and more. Some of the GPU-based FNN implementations (Sec. 5.16–5.19) have greatly contributed to recent successes in contests for pattern recognition (Sec. 5.19–5.22), image segmentation (Sec. 5.21), and object detection (Sec. 5.21–5.22). 5 Supervised NNs, Some Helped by Unsupervised NNs The main focus of current practical applications is on Supervised Learning (SL), which has domi- nated recent pattern recognition contests (Sec. 5.17–5.23). Several methods, however, use additional Unsupervised Learning (UL) to facilitate SL (Sec. 5.7, 5.10, 5.15). It does make sense to treat SL and 8",
      "heading_level": "H3",
      "confidence": 10,
      "word_count": 557,
      "start_page": 8,
      "relevance_score": 1.0,
      "importance_rank": 1
    },
    {
      "document": "1B",
      "section_title": "2013);compareearlierefﬁcientmethodsforCNNs",
      "page_number": 25,
      "content": "spends over 10% of GDP on healthcare (> 6 trillion USD per year), much of it on medical diagnosis through expensive experts. Partial automation of this could not only save lots of money, but also make expert diagnostics accessible to many who currently cannot afford it. It is gratifying to observe that today deep NNs may actually help to improve healthcare and perhaps save human lives. 2012 also saw the ﬁrst pure image segmentation contest won by DL (Ciresan et al., 2012a), again through an GPU-MPCNN ensemble (Segmentation of Neuronal Structures in EM Stacks Challenge, 2012).2 EM stacks are relevant for the recently approved huge brain projects in Europe and the US (e.g., Markram, 2012). Given electron microscopy images of stacks of thin slices of animal brains, the goal is to build a detailed 3D model of the brain’s neurons and dendrites. But human experts need many hours and days and weeks to annotate the images: Which parts depict neuronal membranes? Which parts are irrelevant background? This needs to be automated (e.g., Turaga et al., 2010). Deep Multi-Column GPU-MPCNNs learned to solve this task through experience with many training images, and won the contest on all three evaluation metrics by a large margin, with superhu- man performance in terms of pixel error. Both object detection (Ciresan et al., 2013) and image segmentation (Ciresan et al., 2012a) proﬁt from fast MPCNN-based image scans that avoid redundant computations. Recent MPCNN scanners speed up naive implementations by up to three orders of magnitude (Masci et al., 2013; Giusti et al., 2013); compare earlier efﬁcient methods for CNNs without MP (Vaillant et al., 1994). Also in 2012, a system consisting of growing deep FNNs and 2D-BRNNs (Di Lena et al., 2012) won the CASP 2012 contest on protein contact map prediction. On the IAM-OnDoDB benchmark, LSTM RNNs (Sec. 5.13) outperformed all other methods (HMMs, SVMs) on online mode detec- tion (Otte et al., 2012; Indermuhle et al., 2012) and keyword spotting (Indermuhle et al., 2011). On the long time lag problem of language modelling, LSTM RNNs outperformed all statistical approaches on the IAM-DB benchmark (Frinken et al., 2012); improved results were later obtained through a combination of NNs and HMMs (Zamora-Martnez et al., 2014). Compare earlier RNNs for object recognition through iterative image interpretation (Behnke and Rojas, 1998; Behnke, 2002, 2003b); see also more recent publications (Wyatte et al., 2012; OReilly et al., 2013) extending work on bio- logically plausible learning rules for RNNs (O’Reilly, 1996). 5.22 2013-: More Contests and Benchmark Records A stack (Fernandez et al., 2007; Graves and Schmidhuber, 2009) (Sec. 5.10) of bi-directional LSTM RNNs (Graves and Schmidhuber, 2005) trained by CTC (Sec. 5.13, 5.17) broke a famous TIMIT speech (phoneme) recognition record, achieving 17.7% test set error rate (Graves et al., 2013), despite thousands of man years previously spent on Hidden Markov Model (HMMs)-based speech recognition research. Compare earlier DBN results (Sec. 5.15). CTC-LSTM also helped to score ﬁrst at NIST’s OpenHaRT2013 evaluation (Bluche et al., 2014). For optical character recognition (OCR), LSTM RNNs outperformed commercial recognizers of his- torical data (Breuel et al., 2013). LSTM-based systems also set benchmark records in language iden- tiﬁcation (Gonzalez-Dominguez et al., 2014), medium-vocabulary speech recognition (Geiger et al., 2014), prosody contour prediction (Fernandez et al., 2014), audio onset detection (Marchi et al., 2014), text-to-speech synthesis (Fan et al., 2014), and social signal classiﬁcation (Brueckner and Schulter, 2014). An LSTM RNN was used to estimate the state posteriors of an HMM; this system beat the previous state of the art in large vocabulary speech recognition (Sak et al., 2014b,a). Another LSTM RNN with hundreds of millions of connections was used to rerank hypotheses of a statistical machine translation 2It should be mentioned, however, that LSTM RNNs already performed simultaneous segmentation and recognition when they became the ﬁrst recurrent Deep Learners to win ofﬁcial international pattern recognition contests—see Sec. 5.17. 25",
      "heading_level": "H3",
      "confidence": 7,
      "word_count": 647,
      "start_page": 25,
      "relevance_score": 1.0,
      "importance_rank": 2
    },
    {
      "document": "1B",
      "section_title": "Methodusinveniendi",
      "page_number": 46,
      "content": "Egorova, A., Gloye, A., G¨oktekin, C., Liers, A., Luft, M., Rojas, R., Simon, M., Tenchio, O., and Wiesel, F. (2004). FU-Fighters Small Size 2004, Team Description. RoboCup 2004 Symposium: Papers and Team Description Papers. CD edition. Elfwing, S., Otsuka, M., Uchibe, E., and Doya, K. (2010). Free-energy based reinforcement learning for vision-based navigation with high-dimensional sensory inputs. In Neural Information Process- ing. Theory and Algorithms (ICONIP), volume 1, pages 215–222. Springer. Eliasmith, C. (2013). How to build a brain: A neural architecture for biological cognition. Oxford University Press, New York, NY. Eliasmith, C., Stewart, T. C., Choo, X., Bekolay, T., DeWolf, T., Tang, Y., and Rasmussen, D. (2012). A large-scale model of the functioning brain. Science, 338(6111):1202–1205. Elman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2):179–211. Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., and Bengio, S. (2010). Why does unsupervised pre-training help deep learning? J. Mach. Learn. Res., 11:625–660. Escalante-B., A. N. and Wiskott, L. (2013). How to solve classiﬁcation and regression problems on high-dimensional data with a supervised extension of slow feature analysis. Journal of Machine Learning Research, 14:3683–3719. Eubank, R. L. (1988). Spline smoothing and nonparametric regression. In Farlow, S., editor, Self- Organizing Methods in Modeling. Marcel Dekker, New York. Euler, L. (1744). Methodus inveniendi. Eyben, F., Weninger, F., Squartini, S., and Schuller, B. (2013). Real-life voice activity detection with LSTM recurrent neural networks and an application to Hollywood movies. In Proc. 38th IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2013, Vancouver, Canada, pages 483–487. Faggin, F. (1992). Neural network hardware. In International Joint Conference on Neural Networks (IJCNN), volume 1, page 153. Fahlman, S. E. (1988). An empirical study of learning speed in back-propagation networks. Technical Report CMU-CS-88-162, Carnegie-Mellon Univ. Fahlman, S. E. (1991). The recurrent cascade-correlation learning algorithm. In Lippmann, R. P., Moody, J. E., and Touretzky, D. S., editors, Advances in Neural Information Processing Systems (NIPS) 3, pages 190–196. Morgan Kaufmann. Falconbridge, M. S., Stamps, R. L., and Badcock, D. R. (2006). A simple Hebbian/anti-Hebbian network learns the sparse, independent components of natural images. Neural Computation, 18(2):415–429. Fan, Y., Qian, Y., Xie, F., and Soong, F. K. (2014). TTS synthesis with bidirectional LSTM based recurrent neural networks. In Proc. Interspeech. Farabet, C., Couprie, C., Najman, L., and LeCun, Y. (2013). Learning hierarchical features for scene labeling. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1915–1929. Farlow, S. J. (1984). Self-organizing methods in modeling: GMDH type algorithms, volume 54. CRC Press. 46 Feldkamp, L. A., Prokhorov, D. V., Eagen, C. F., and Yuan, F. (1998). Enhanced multi-stream Kalman ﬁlter training for recurrent networks. In Nonlinear Modeling, pages 29–53. Springer. Feldkamp, L. A., Prokhorov, D. V., and Feldkamp, T. M. (2003). Simple and conditioned adaptive behavior from Kalman ﬁlter trained recurrent networks. Neural Networks, 16(5):683–689. Feldkamp, L. A. and Puskorius, G. V. (1998). A signal processing framework based on dynamic neural networks with application to problems in adaptation, ﬁltering, and classiﬁcation. Proceedings of the IEEE, 86(11):2259–2277. Felleman, D. J. and Van Essen, D. C. (1991). Distributed hierarchical processing in the primate cerebral cortex. Cerebral Cortex, 1(1):1–47. Fernandez, R., Rendel, A., Ramabhadran, B., and Hoory, R. (2014). Prosody contour prediction with Long Short-Term Memory, bi-directional, deep recurrent neural networks. In Proc. Interspeech. Fern´andez, S., Graves, A., and Schmidhuber, J. (2007). An application of recurrent neural networks to discriminative keyword spotting. In Proc. ICANN (2), pages 220–229. Fernandez, S., Graves, A., and Schmidhuber, J. (2007). Sequence labelling in structured domains with hierarchical recurrent neural networks. In Proceedings of the 20th International Joint Conference on Artiﬁcial Intelligence (IJCAI). Field, D. J. (1987). Relations between the statistics of natural images and the response properties of cortical cells. Journal of the Optical Society of America, 4:2379–2394. Field, D. J. (1994). What is the goal of sensory coding? Neural Computation, 6:559–601. Fieres, J., Schemmel, J., and Meier, K. (2008). Realizing biological spiking network models in a conﬁgurable wafer-scale hardware system. In IEEE International Joint Conference on Neural Networks, pages 969–976. Fine, S., Singer, Y., and Tishby, N. (1998). The hierarchical hidden Markov model: Analysis and applications. Machine Learning, 32(1):41–62. Fischer, A. and Igel, C. (2014). Training restricted Boltzmann machines: An introduction.",
      "heading_level": "H3",
      "confidence": 10,
      "word_count": 696,
      "start_page": 46,
      "relevance_score": 1.0,
      "importance_rank": 3
    },
    {
      "document": "1B",
      "section_title": "Psychologicalreview",
      "page_number": 74,
      "content": "Roggen, D., Hofmann, S., Thoma, Y., and Floreano, D. (2003). Hardware spiking neural network with run-time reconﬁgurable connectivity in an autonomous robot. In Proc. NASA/DoD Conference on Evolvable Hardware, 2003, pages 189–198. IEEE. Rohwer, R. (1989). The ‘moving targets’ training method. In Kindermann, J. and Linden, A., edi- tors, Proceedings of ‘Distributed Adaptive Neural Information Processing’, St.Augustin, 24.-25.5,. Oldenbourg. Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6):386. Rosenblatt, F. (1962). Principles of Neurodynamics. Spartan, New York. Roux, L., Racoceanu, D., Lomenie, N., Kulikova, M., Irshad, H., Klossa, J., Capron, F., Genestie, C., Naour, G. L., and Gurcan, M. N. (2013). Mitosis detection in breast cancer histological images - an ICPR 2012 contest. J. Pathol. Inform., 4:8. Rubner, J. and Schulten, K. (1990). Development of feature detectors by self-organization: A network model. Biological Cybernetics, 62:193–199. R¨uckstieß, T., Felder, M., and Schmidhuber, J. (2008). State-Dependent Exploration for policy gra- dient methods. In et al., W. D., editor, European Conference on Machine Learning (ECML) and Principles and Practice of Knowledge Discovery in Databases 2008, Part II, LNAI 5212, pages 234–249. Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning internal representations by error propagation. In Rumelhart, D. E. and McClelland, J. L., editors, Parallel Distributed Processing, volume 1, pages 318–362. MIT Press. Rumelhart, D. E. and Zipser, D. (1986). Feature discovery by competitive learning. In Parallel Distributed Processing, pages 151–193. MIT Press. Rummery, G. and Niranjan, M. (1994). On-line Q-learning using connectionist sytems. Technical Report CUED/F-INFENG-TR 166, Cambridge University, UK. Russell, S. J., Norvig, P., Canny, J. F., Malik, J. M., and Edwards, D. D. (1995). Artiﬁcial Intelligence: a Modern Approach, volume 2. Englewood Cliffs: Prentice Hall. Saito, K. and Nakano, R. (1997). Partial BFGS update and efﬁcient step-length calculation for three- layer neural networks. Neural Computation, 9(1):123–141. Sak, H., Senior, A., and Beaufays, F. (2014a). Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling. In Proc. Interspeech. Sak, H., Vinyals, O., Heigold, G., Senior, A., McDermott, E., Monga, R., and Mao, M. (2014b). Se- quence discriminative distributed training of Long Short-Term Memory recurrent neural networks. In Proc. Interspeech. Salakhutdinov, R. and Hinton, G. (2009). Semantic hashing. Int. J. Approx. Reasoning, 50(7):969–",
      "heading_level": "H3",
      "confidence": 10,
      "word_count": 376,
      "start_page": 74,
      "relevance_score": 1.0,
      "importance_rank": 4
    },
    {
      "document": "1B",
      "section_title": "5.12 1994:EarlyContest-WinningNNs",
      "page_number": 18,
      "content": "greatly reduce problem depth. Compare earlier BP-based ﬁne-tuning of NNs initialized by rules of propositional logic (Shavlik and Towell, 1989) (Sec. 5.6.1). There is a way of compressing higher levels down into lower levels, thus fully or partially col- lapsing the RNN stack. The trick is to retrain a lower-level RNN to continually imitate (predict) the hidden units of an already trained, slower, higher-level RNN (the “conscious” chunker), through ad- ditional predictive output neurons (Schmidhuber, 1992b). This helps the lower RNN (the automatizer) to develop appropriate, rarely changing memories that may bridge very long time lags. Again, this procedure can greatly reduce the required depth of the BP process. The 1991 system was a working Deep Learner in the modern post-2000 sense, and also a ﬁrst Neural Hierarchical Temporal Memory (HTM). It is conceptually similar to earlier AE hierarchies (1987, Sec. 5.7) and later Deep Belief Networks (2006, Sec. 5.15), but more general in the sense that it uses sequence-processing RNNs instead of FNNs with unchanging inputs. More recently, well-known entrepreneurs (Hawkins and George, 2006; Kurzweil, 2012) also got interested in HTMs; compare also hierarchical HMMs (e.g., Fine et al., 1998), as well as later UL-based recurrent sys- tems (Klapper-Rybicka et al., 2001; Steil, 2007; Klampﬂand Maass, 2013; Young et al., 2014). Clockwork RNNs (Koutn´ık et al., 2014) also consist of interacting RNN modules with different clock rates, but do not use UL to set those rates. Stacks of RNNs were used in later work on SL with great success, e.g., Sec. 5.13, 5.16, 5.17, 5.22. 5.11 1992: Max-Pooling (MP): Towards MPCNNs (Compare Sec. 5.16, 5.19) The Neocognitron (Sec. 5.4) inspired the Cresceptron (Weng et al., 1992), which adapts its topol- ogy during training (Sec. 5.6.3); compare the incrementally growing and shrinking GMDH networks (1965, Sec. 5.3). Instead of using alternative local subsampling or WTA methods (e.g., Fukushima, 1980; Schmid- huber, 1989b; Maass, 2000; Fukushima, 2013a), the Cresceptron uses Max-Pooling (MP) layers. Here a 2-dimensional layer or array of unit activations is partitioned into smaller rectangular arrays. Each is replaced in a downsampling layer by the activation of its maximally active unit. A later, more com- plex version of the Cresceptron (Weng et al., 1997) also included “blurring” layers to improve object location tolerance. The neurophysiologically plausible topology of the feedforward HMAX model (Riesenhuber and Poggio, 1999) is very similar to the one of the 1992 Cresceptron (and thus to the 1979 Neocognitron). HMAX does not learn though. Its units have hand-crafted weights; biologically plausible learning rules were later proposed for similar models (e.g., Serre et al., 2002; Teichmann et al., 2012). When CNNs or convnets (Sec. 5.4, 5.8) are combined with MP, they become Cresceptron-like or HMAX-like MPCNNs with alternating convolutional and max-pooling layers. Unlike Cresceptron and HMAX, however, MPCNNs are trained by BP (Sec. 5.5, 5.16) (Ranzato et al., 2007). Advantages of doing this were pointed out subsequently (Scherer et al., 2010). BP-trained MPCNNs have become central to many modern, competition-winning, feedforward, visual Deep Learners (Sec. 5.17, 5.19– 5.23). 5.12 1994: Early Contest-Winning NNs Back in the 1990s, certain NNs already won certain controlled pattern recognition contests with secret test sets. Notably, an NN with internal delay lines won the Santa Fe time-series competition on chaotic intensity pulsations of an NH3 laser (Wan, 1994; Weigend and Gershenfeld, 1993). No very deep CAPs (Sec. 3) were needed though. 18 5.13 1995: Supervised Recurrent Very Deep Learner (LSTM RNN) Supervised Long Short-Term Memory (LSTM) RNN (Hochreiter and Schmidhuber, 1997b; Gers et al., 2000; P´erez-Ortiz et al., 2003) could eventually perform similar feats as the deep RNN hierarchy of 1991 (Sec. 5.10), overcoming the Fundamental Deep Learning Problem (Sec. 5.9) without any unsupervised pre-training. LSTM could also learn DL tasks without local sequence predictability (and thus unlearnable by the partially unsupervised 1991 History Compressor, Sec. 5.10), dealing with very deep problems (Sec. 3) (e.g., Gers et al., 2002). The basic LSTM idea is very simple. Some of the units are called Constant Error Carousels (CECs). Each CEC uses as an activation function f, the identity function, and has a connection to itself with ﬁxed weight of 1.0. Due to f’s constant derivative of 1.0, errors backpropagated through a CEC cannot vanish or explode (Sec. 5.9) but stay as they are (unless they “ﬂow out” of the CEC to other, typically adaptive parts of the NN). CECs are connected to several nonlinear adaptive units (some with multiplicative activation functions) needed for learning nonlinear behavior. Weight changes of these units often proﬁt from error signals propagated far back in time through CECs. CECs are the main reason why LSTM nets can learn to discover the importance of (and memorize) events that happened thousands of discrete time steps ago, while previous RNNs already failed in case of minimal time lags of 10 steps. Many different LSTM variants and topologies are allowed. It is possible to evolve good problem- speciﬁc topologies (Bayer et al., 2009). Some LSTM variants also use modiﬁable self-connections of CECs (Gers and Schmidhuber, 2001). To a certain extent, LSTM is biologically plausible (O’Reilly, 2003). LSTM learned to solve many previously unlearnable DL tasks involving: Recognition of the temporal order of widely sep- arated events in noisy input streams; Robust storage of high-precision real numbers across extended time intervals; Arithmetic operations on continuous input streams; Extraction of information con- veyed by the temporal distance between events; Recognition of temporally extended patterns in noisy input sequences (Hochreiter and Schmidhuber, 1997b; Gers et al., 2000); Stable generation of pre- cisely timed rhythms, as well as smooth and non-smooth periodic trajectories (Gers and Schmidhuber, 2000). LSTM clearly outperformed previous RNNs on tasks that require learning the rules of regu- lar languages describable by deterministic Finite State Automata (FSAs) (Watrous and Kuhn, 1992; Casey, 1996; Siegelmann, 1992; Blair and Pollack, 1997; Kalinke and Lehmann, 1998; Zeng et al., 1994; Manolios and Fanelli, 1994; Omlin and Giles, 1996; Vahed and Omlin, 2004), both in terms of reliability and speed. LSTM also worked on tasks involving context free languages (CFLs) that cannot be represented by HMMs or similar FSAs discussed in the RNN literature (Sun et al., 1993b; Wiles and Elman, 1995; Andrews et al., 1995; Steijvers and Grunwald, 1996; Tonkes and Wiles, 1997; Rodriguez et al., 1999; Rodriguez and Wiles, 1998). CFL recognition (Lee, 1996) requires the functional equivalent of a run- time stack. Some previous RNNs failed to learn small CFL training sets (Rodriguez and Wiles, 1998). Those that did not (Rodriguez et al., 1999; Bod´en and Wiles, 2000) failed to extract the general rules, and did not generalize well on substantially larger test sets. Similar for context-sensitive languages (CSLs) (e.g., Chalup and Blair, 2003). LSTM generalized well though, requiring only the 30 shortest exemplars (n ≤10) of the CSL anbncn to correctly predict the possible continuations of sequence preﬁxes for n up to 1000 and more. A combination of a decoupled extended Kalman ﬁlter (Kalman, 1960; Williams, 1992b; Puskorius and Feldkamp, 1994; Feldkamp et al., 1998; Haykin, 2001; Feld- kamp et al., 2003) and an LSTM RNN (P´erez-Ortiz et al., 2003) learned to deal correctly with values of n up to 10 million and more. That is, after training the network was able to read sequences of 30,000,000 symbols and more, one symbol at a time, and ﬁnally detect the subtle differences be- tween legal strings such as a10,000,000b10,000,000c10,000,000 and very similar but illegal strings such as a10,000,000b9,999,999c10,000,000. Compare also more recent RNN algorithms able to deal with long 19 time lags (Sch¨afer et al., 2006; Martens and Sutskever, 2011; Zimmermann et al., 2012; Koutn´ık et al., 2014). Bi-directional RNNs (BRNNs) (Schuster and Paliwal, 1997; Schuster, 1999) are designed for in- put sequences whose starts and ends are known in advance, such as spoken sentences to be labeled by their phonemes; compare (Fukada et al., 1999). To take both past and future context of each sequence element into account, one RNN processes the sequence from start to end, the other backwards from end to start. At each time step their combined outputs predict the corresponding label (if there is any). BRNNs were successfully applied to secondary protein structure prediction (Baldi et al., 1999). DAG-RNNs (Baldi and Pollastri, 2003; Wu and Baldi, 2008) generalize BRNNs to multiple dimen- sions. They learned to predict properties of small organic molecules (Lusci et al., 2013) as well as protein contact maps (Tegge et al., 2009), also in conjunction with a growing deep FNN (Di Lena et al., 2012) (Sec. 5.21). BRNNs and DAG-RNNs unfold their full potential when combined with the LSTM concept (Graves and Schmidhuber, 2005, 2009; Graves et al., 2009). Particularly successful in recent competitions are stacks (Sec. 5.10) of LSTM RNNs (Fernan- dez et al., 2007; Graves and Schmidhuber, 2009) trained by Connectionist Temporal Classiﬁca- tion (CTC) (Graves et al., 2006), a gradient-based method for ﬁnding RNN weights that maxi- mize the probability of teacher-given label sequences, given (typically much longer and more high- dimensional) streams of real-valued input vectors. CTC-LSTM performs simultaneous segmentation (alignment) and recognition (Sec. 5.22). In the early 2000s, speech recognition was dominated by HMMs combined with FNNs (e.g., Bourlard and Morgan, 1994). Nevertheless, when trained from scratch on utterances from the TIDIG- ITS speech database, in 2003 LSTM already obtained results comparable to those of HMM-based systems (Graves et al., 2003; Beringer et al., 2005; Graves et al., 2006). In 2007, LSTM outperformed HMMs in keyword spotting tasks (Fern´andez et al., 2007); compare recent improvements (Indermuhle et al., 2011; W¨ollmer et al., 2013). By 2013, LSTM also achieved best known results on the famous TIMIT phoneme recognition benchmark (Graves et al., 2013) (Sec. 5.22). Recently, LSTM RNN / HMM hybrids obtained best known performance on medium-vocabulary (Geiger et al., 2014) and large-vocabulary speech recognition (Sak et al., 2014a). LSTM is also applicable to robot localization (F¨orster et al., 2007), robot control (Mayer et al., 2008), online driver distraction detection (W¨ollmer et al., 2011), and many other tasks. For example, it helped to improve the state of the art in diverse applications such as protein analysis (Hochreiter and Obermayer, 2005), handwriting recognition (Graves et al., 2008, 2009; Graves and Schmidhuber, 2009; Bluche et al., 2014), voice activity detection (Eyben et al., 2013), optical character recogni- tion (Breuel et al., 2013), language identiﬁcation (Gonzalez-Dominguez et al., 2014), prosody contour prediction (Fernandez et al., 2014), audio onset detection (Marchi et al., 2014), text-to-speech syn- thesis (Fan et al., 2014), social signal classiﬁcation (Brueckner and Schulter, 2014), machine transla- tion (Sutskever et al., 2014), and others. RNNs can also be used for metalearning (Schmidhuber, 1987; Schaul and Schmidhuber, 2010; Prokhorov et al., 2002), because they can in principle learn to run their own weight change algo- rithm (Schmidhuber, 1993a). A successful metalearner (Hochreiter et al., 2001b) used an LSTM RNN to quickly learn a learning algorithm for quadratic functions (compare Sec. 6.8). Recently, LSTM RNNs won several international pattern recognition competitions and set nu- merous benchmark records on large and complex data sets, e.g., Sec. 5.17, 5.21, 5.22. Gradient- based LSTM is no panacea though—other methods sometimes outperformed it at least on certain tasks (Jaeger, 2004; Schmidhuber et al., 2007; Martens and Sutskever, 2011; Pascanu et al., 2013b; Koutn´ık et al., 2014); compare Sec. 5.20. 20 5.14 2003: More Contest-Winning/Record-Setting NNs; Successful Deep NNs In the decade around 2000, many practical and commercial pattern recognition applications were dominated by non-neural machine learning methods such as Support Vector Machines (SVMs) (Vap- nik, 1995; Sch¨olkopf et al., 1998). Nevertheless, at least in certain domains, NNs outperformed other techniques. A Bayes NN (Neal, 2006) based on an ensemble (Breiman, 1996; Schapire, 1990; Wolpert, 1992; Hashem and Schmeiser, 1992; Ueda, 2000; Dietterich, 2000a) of NNs won the NIPS 2003 Feature Selection Challenge with secret test set (Neal and Zhang, 2006). The NN was not very deep though— it had two hidden layers and thus rather shallow CAPs (Sec. 3) of depth 3. Important for many present competition-winning pattern recognisers (Sec. 5.19, 5.21, 5.22) were developments in the CNN department. A BP-trained (LeCun et al., 1989) CNN (Sec. 5.4, Sec. 5.8) set a new MNIST record of 0.4% (Simard et al., 2003), using training pattern deformations (Baird, 1990) but no unsupervised pre-training (Sec. 5.7, 5.10, 5.15). A standard BP net achieved 0.7% (Simard et al., 2003). Again, the corresponding CAP depth was low. Compare further improvements in Sec. 5.16, 5.18, 5.19. Good image interpretation results (Behnke, 2003b) were achieved with rather deep NNs trained by the BP variant R-prop (Riedmiller and Braun, 1993) (Sec. 5.6.2); here feedback through recurrent connections helped to improve image interpretation. FNNs with CAP depth up to 6 were used to successfully classify high-dimensional data (Vieira and Barradas, 2003). Deep LSTM RNNs started to obtain certain ﬁrst speech recognition results comparable to those of HMM-based systems (Graves et al., 2003); compare Sec. 5.13, 5.16, 5.21, 5.22. 5.15 2006/7: UL For Deep Belief Networks / AE Stacks Fine-Tuned by BP While learning networks with numerous non-linear layers date back at least to 1965 (Sec. 5.3), and ex- plicit DL research results have been published at least since 1991 (Sec. 5.9, 5.10), the expression Deep Learning was actually coined around 2006, when unsupervised pre-training of deep FNNs helped to accelerate subsequent SL through BP (Hinton and Salakhutdinov, 2006; Hinton et al., 2006). Compare earlier terminology on loading deep networks (S´ıma, 1994; Windisch, 2005) and learning deep mem- ories (Gomez and Schmidhuber, 2005). Compare also BP-based (Sec. 5.5) ﬁne-tuning (Sec. 5.6.1) of (not so deep) FNNs pre-trained by competitive UL (Maclin and Shavlik, 1995). The Deep Belief Network (DBN) is a stack of Restricted Boltzmann Machines (RBMs) (Smolen- sky, 1986), which in turn are Boltzmann Machines (BMs) (Hinton and Sejnowski, 1986) with a single layer of feature-detecting units; compare also Higher-Order BMs (Memisevic and Hinton, 2010). Each RBM perceives pattern representations from the level below and learns to encode them in un- supervised fashion. At least in theory under certain assumptions, adding more layers improves a bound on the data’s negative log probability (Hinton et al., 2006) (equivalent to the data’s description length—compare the corresponding observation for RNN stacks, Sec. 5.10). There are extensions for Temporal RBMs (Sutskever et al., 2008). Without any training pattern deformations (Sec. 5.14), a DBN ﬁne-tuned by BP achieved 1.2% error rate (Hinton and Salakhutdinov, 2006) on the MNIST handwritten digits (Sec. 5.8, 5.14). This result helped to arouse interest in DBNs. DBNs also achieved good results on phoneme recognition, with an error rate of 26.7% on the TIMIT core test set (Mohamed and Hinton, 2010); compare further improvements through FNNs (Hinton et al., 2012a; Deng and Yu, 2014) and LSTM RNNs (Sec. 5.22). A DBN-based technique called Semantic Hashing (Salakhutdinov and Hinton, 2009) maps se- mantically similar documents (of variable size) to nearby addresses in a space of document rep- resentations. It outperformed previous searchers for similar documents, such as Locality Sensitive Hashing (Buhler, 2001; Datar et al., 2004). See the RBM/DBN tutorial (Fischer and Igel, 2014). 21 Autoencoder (AE) stacks (Ballard, 1987) (Sec. 5.7) became a popular alternative way of pre- training deep FNNs in unsupervised fashion, before ﬁne-tuning (Sec. 5.6.1) them through BP (Sec. 5.5) (Bengio et al., 2007; Vincent et al., 2008; Erhan et al., 2010). Sparse coding (Sec. 5.6.4) was formulated as a combination of convex optimization problems (Lee et al., 2007a). Recent surveys of stacked RBM and AE methods focus on post-2006 developments (Bengio, 2009; Arel et al., 2010). Unsupervised DBNs and AE stacks are conceptually similar to, but in a certain sense less general than, the unsupervised RNN stack-based History Compressor of 1991 (Sec. 5.10), which can process and re-encode not only stationary input patterns, but entire pattern sequences. 5.16 2006/7: Improved CNNs / GPU-CNNs / BP for MPCNNs / LSTM Stacks Also in 2006, a BP-trained (LeCun et al., 1989) CNN (Sec. 5.4, Sec. 5.8) set a new MNIST record of 0.39% (Ranzato et al., 2006), using training pattern deformations (Sec. 5.14) but no unsupervised pre-training. Compare further improvements in Sec. 5.18, 5.19. Similar CNNs were used for off- road obstacle avoidance (LeCun et al., 2006). A combination of CNNs and TDNNs later learned to map ﬁxed-size representations of variable-size sentences to features relevant for language processing, using a combination of SL and UL (Collobert and Weston, 2008). 2006 also saw an early GPU-based CNN implementation (Chellapilla et al., 2006) up to 4 times faster than CPU-CNNs; compare also earlier GPU implementations of standard FNNs with a reported speed-up factor of 20 (Oh and Jung, 2004). GPUs or graphics cards have become more and more important for DL in subsequent years (Sec. 5.18–5.22). In 2007, BP (Sec. 5.5) was applied for the ﬁrst time (Ranzato et al., 2007) to Neocognitron- inspired (Sec. 5.4), Cresceptron-like (or HMAX-like) MPCNNs (Sec. 5.11) with alternating convo- lutional and max-pooling layers. BP-trained MPCNNs have become an essential ingredient of many modern, competition-winning, feedforward, visual Deep Learners (Sec. 5.17, 5.19–5.23). Also in 2007, hierarchical stacks of LSTM RNNs were introduced (Fernandez et al., 2007). They can be trained by hierarchical Connectionist Temporal Classiﬁcation (CTC) (Graves et al., 2006). For tasks of sequence labelling, every LSTM RNN level (Sec. 5.13) predicts a sequence of labels fed to the next level. Error signals at every level are back-propagated through all the lower levels. On spoken digit recognition, LSTM stacks outperformed HMMs, despite making fewer assumptions about the domain. LSTM stacks do not necessarily require unsupervised pre-training like the earlier UL-based RNN stacks (Schmidhuber, 1992b) of Sec. 5.10. 5.17 2009: First Ofﬁcial Competitions Won by RNNs, and with MPCNNs Stacks of LSTM RNNs trained by CTC (Sec. 5.13, 5.16) became the ﬁrst RNNs to win ofﬁcial interna- tional pattern recognition contests (with secret test sets known only to the organisers). More precisely, three connected handwriting competitions at ICDAR 2009 in three different languages (French, Arab, Farsi) were won by deep LSTM RNNs without any a priori linguistic knowledge, performing simul- taneous segmentation and recognition. Compare (Graves and Schmidhuber, 2005; Graves et al., 2009; Schmidhuber et al., 2011; Graves et al., 2013; Graves and Jaitly, 2014) (Sec. 5.22). To detect human actions in surveillance videos, a 3-dimensional CNN (e.g., Jain and Seung, 2009; Prokhorov, 2010), combined with SVMs, was part of a larger system (Yang et al., 2009) using a bag of features approach (Nowak et al., 2006) to extract regions of interest. The system won three 2009 TRECVID competitions. These were possibly the ﬁrst ofﬁcial international contests won with the help of (MP)CNNs (Sec. 5.16). An improved version of the method was published later (Ji et al., 2013). 2009 also saw a GPU-DBN implementation (Raina et al., 2009) orders of magnitudes faster than previous CPU-DBNs (see Sec. 5.15); see also (Coates et al., 2013). The Convolutional DBN (Lee 22 et al., 2009a) (with a probabilistic variant of MP, Sec. 5.11) combines ideas from CNNs and DBNs, and was successfully applied to audio classiﬁcation (Lee et al., 2009b). 5.18 2010: Plain Backprop (+ Distortions) on GPU Breaks MNIST Record In 2010, a new MNIST (Sec. 5.8) record of 0.35% error rate was set by good old BP (Sec. 5.5) in deep but otherwise standard NNs (Ciresan et al., 2010), using neither unsupervised pre-training (e.g., Sec. 5.7, 5.10, 5.15) nor convolution (e.g., Sec. 5.4, 5.8, 5.14, 5.16). However, training pattern deformations (e.g., Sec. 5.14) were important to generate a big training set and avoid overﬁtting. This success was made possible mainly through a GPU implementation of BP that was up to 50 times faster than standard CPU versions. A good value of 0.95% was obtained without distortions except for small saccadic eye movement-like translations—compare Sec. 5.15. Since BP was 3-5 decades old by then (Sec. 5.5), and pattern deformations 2 decades (Baird, 1990) (Sec. 5.14), these results seemed to suggest that advances in exploiting modern computing hardware were more important than advances in algorithms. 5.19 2011: MPCNNs on GPU Achieve Superhuman Vision Performance In 2011, a ﬂexible GPU-implementation (Ciresan et al., 2011a) of Max-Pooling (MP) CNNs or Con- vnets was described (a GPU-MPCNN), building on earlier MP work (Weng et al., 1992) (Sec. 5.11) CNNs (Fukushima, 1979; LeCun et al., 1989) (Sec. 5.4, 5.8, 5.16), and on early GPU-based CNNs without MP (Chellapilla et al., 2006) (Sec. 5.16); compare early GPU-NNs (Oh and Jung, 2004) and GPU-DBNs (Raina et al., 2009) (Sec. 5.17). MPCNNs have alternating convolutional layers (Sec. 5.4) and max-pooling layers (MP, Sec. 5.11) topped by standard fully connected layers. All weights are trained by BP (Sec. 5.5, 5.8, 5.16) (Ranzato et al., 2007; Scherer et al., 2010). GPU-MPCNNs have become essential for many contest-winning FNNs (Sec. 5.21, Sec. 5.22). Multi-Column GPU-MPCNNs (Ciresan et al., 2011b) are committees (Breiman, 1996; Schapire, 1990; Wolpert, 1992; Hashem and Schmeiser, 1992; Ueda, 2000; Dietterich, 2000a) of GPU- MPCNNs with simple democratic output averaging. Several MPCNNs see the same input; their output vectors are used to assign probabilities to the various possible classes. The class with the on average highest probability is chosen as the system’s classiﬁcation of the present input. Compare earlier, more sophisticated ensemble methods (Schapire, 1990), the contest-winning ensemble Bayes-NN (Neal, 2006) of Sec. 5.14, and recent related work (Shao et al., 2014). An ensemble of GPU-MPCNNs was the ﬁrst system to achieve superhuman visual pattern recog- nition (Ciresan et al., 2011b, 2012b) in a controlled competition, namely, the IJCNN 2011 trafﬁc sign recognition contest in San Jose (CA) (Stallkamp et al., 2011, 2012). This is of interest for fully autonomous, self-driving cars in trafﬁc (e.g., Dickmanns et al., 1994). The GPU-MPCNN ensem- ble obtained 0.56% error rate and was twice better than human test subjects, three times better than the closest artiﬁcial NN competitor (Sermanet and LeCun, 2011), and six times better than the best non-neural method. A few months earlier, the qualifying round was won in a 1st stage online competition, albeit by a much smaller margin: 1.02% (Ciresan et al., 2011b) vs 1.03% for second place (Sermanet and LeCun, 2011). After the deadline, the organisers revealed that human performance on the test set was 1.19%. That is, the best methods already seemed human-competitive. However, during the qualifying it was possible to incrementally gain information about the test set by probing it through repeated submissions. This is illustrated by better and better results obtained by various teams over time (Stallkamp et al., 2012) (the organisers eventually imposed a limit of 10 resubmissions). In the ﬁnal competition this was not possible. 23 This illustrates a general problem with benchmarks whose test sets are public, or at least can be probed to some extent: competing teams tend to overﬁt on the test set even when it cannot be directly used for training, only for evaluation. In 1997 many thought it a big deal that human chess world champion Kasparov was beaten by an IBM computer. But back then computers could not at all compete with little kids in visual pat- tern recognition, which seems much harder than chess from a computational perspective. Of course, the trafﬁc sign domain is highly restricted, and kids are still much better general pattern recognis- ers. Nevertheless, by 2011, deep NNs could already learn to rival them in important limited visual domains. An ensemble of GPU-MPCNNs was also the ﬁrst method to achieve human-competitive perfor- mance (around 0.2%) on MNIST (Ciresan et al., 2012c). This represented a dramatic improvement, since by then the MNIST record had hovered around 0.4% for almost a decade (Sec. 5.14, 5.16, 5.18). Given all the prior work on (MP)CNNs (Sec. 5.4, 5.8, 5.11, 5.16) and GPU-CNNs (Sec. 5.16), GPU-MPCNNs are not a breakthrough in the scientiﬁc sense. But they are a commercially relevant breakthrough in efﬁcient coding that has made a difference in several contests since 2011. Today, most feedforward competition-winning deep NNs are (ensembles of) GPU-MPCNNs (Sec. 5.21–5.23). 5.20 2011: Hessian-Free Optimization for RNNs Also in 2011 it was shown (Martens and Sutskever, 2011) that Hessian-free optimization (e.g., Møller, 1993; Pearlmutter, 1994; Schraudolph, 2002) (Sec. 5.6.2) can alleviate the Fundamental Deep Learn- ing Problem (Sec. 5.9) in RNNs, outperforming standard gradient-based LSTM RNNs (Sec. 5.13) on several tasks. Compare other RNN algorithms (Jaeger, 2004; Schmidhuber et al., 2007; Pascanu et al., 2013b; Koutn´ık et al., 2014) that also at least sometimes yield better results than steepest descent for LSTM RNNs. 5.21 2012: First Contests Won on ImageNet, Object Detection, Segmentation In 2012, an ensemble of GPU-MPCNNs (Sec. 5.19) achieved best results on the ImageNet classiﬁca- tion benchmark (Krizhevsky et al., 2012), which is popular in the computer vision community. Here relatively large image sizes of 256x256 pixels were necessary, as opposed to only 48x48 pixels for the 2011 trafﬁc sign competition (Sec. 5.19). See further improvements in Sec. 5.22. Also in 2012, the biggest NN so far (109 free parameters) was trained in unsupervised mode (Sec. 5.7, 5.15) on unlabeled data (Le et al., 2012), then applied to ImageNet. The codes across its top layer were used to train a simple supervised classiﬁer, which achieved best results so far on 20,000 classes. Instead of relying on efﬁcient GPU programming, this was done by brute force on 1,000 standard machines with 16,000 cores. So by 2011/2012, excellent results had been achieved by Deep Learners in image recognition and classiﬁcation (Sec. 5.19, 5.21). The computer vision community, however, is especially interested in object detection in large images, for applications such as image-based search engines, or for biomed- ical diagnosis where the goal may be to automatically detect tumors etc in images of human tissue. Object detection presents additional challenges. One natural approach is to train a deep NN classiﬁer on patches of big images, then use it as a feature detector to be shifted across unknown visual scenes, using various rotations and zoom factors. Image parts that yield highly active output units are likely to contain objects similar to those the NN was trained on. 2012 ﬁnally saw the ﬁrst DL system (an ensemble of GPU-MPCNNs, Sec. 5.19) to win a contest on visual object detection (Ciresan et al., 2013) in large images of several million pixels (ICPR 2012 Contest on Mitosis Detection in Breast Cancer Histological Images, 2012; Roux et al., 2013). Such biomedical applications may turn out to be among the most important applications of DL. The world 24",
      "heading_level": "H2",
      "confidence": 7,
      "word_count": 4374,
      "start_page": 18,
      "relevance_score": 0.99,
      "importance_rank": 5
    }
  ],
  "sub_section_analysis": [
    {
      "document": "1B",
      "section_title": "Manymethodsof",
      "refined_text": "3 Learning Hierarchical Representations Through Deep SL, UL, RL Many methods of Good Old-Fashioned Artiﬁcial Intelligence (GOFAI) (Nilsson, 1980) as well as more recent approaches to AI (Russell et al. , 1995) and Machine Learning (Mitchell, 1997) learn hierarchies of more and more abstract data representations. For example, certain methods of syn- tactic pattern recognition (Fu, 1977) such as grammar induction discover hierarchies of formal rules to model observations. The partially (un)supervised Automated Mathematician / EURISKO (Lenat, 1983; Lenat and Brown, 1984) continually learns concepts by combining previously learnt concepts. Often, abstract hierarchical representations are natural by-products of data compression (Sec. Some methods explicitly take into account program runtime (Allender, 1992; Watanabe, 1992; Schmidhuber, 1997, 2002); many consider only programs with constant runtime, written in non-universal programming languages (e. In the NN case, the MDL princi- ple suggests that low NN weight complexity corresponds to high NN probability in the Bayesian view (e. , Baum and Haussler, 1989), without overﬁtting the training data. Many methods have been proposed for regularizing NNs, that is, searching for solution-computing but simple, low-complexity SL NNs (Sec. Several methods, however, use additional Unsupervised Learning (UL) to facilitate SL (Sec",
      "page_number": 8,
      "importance_rank": 1,
      "relevance_score": 1.0,
      "original_length": 3706,
      "refined_length": 1384,
      "domain": "academic"
    },
    {
      "document": "1B",
      "section_title": "2013);compareearlierefﬁcientmethodsforCNNs",
      "refined_text": "spends over 10% of GDP on healthcare (> 6 trillion USD per year), much of it on medical diagnosis through expensive experts. Partial automation of this could not only save lots of money, but also make expert diagnostics accessible to many who currently cannot afford it. It is gratifying to observe that today deep NNs may actually help to improve healthcare and perhaps save human lives. 2012 also saw the ﬁrst pure image segmentation contest won by DL (Ciresan et al., 2012a), again through an GPU-MPCNN ensemble (Segmentation of Neuronal Structures in EM Stacks Challenge, 2012).2 EM stacks are relevant for the recently approved huge brain projects in Europe and the US (e.g., Markram, 2012). Given electron microscopy images of stacks of thin slices of animal brains, the goal is to build a detailed 3D model of the brain’s neurons and dendrites. But human experts need many hours and days and weeks to annotate the images: Which parts depict neuronal membranes? Which parts are irrelevant backg...",
      "page_number": 25,
      "importance_rank": 2,
      "relevance_score": 1.0,
      "original_length": 4201,
      "refined_length": 1003,
      "domain": "academic"
    },
    {
      "document": "1B",
      "section_title": "Methodusinveniendi",
      "refined_text": "Egorova, A., Gloye, A., G¨oktekin, C., Liers, A., Luft, M., Rojas, R., Simon, M., Tenchio, O., and Wiesel, F. (2004). FU-Fighters Small Size 2004, Team Description. RoboCup 2004 Symposium: Papers and Team Description Papers. CD edition. Elfwing, S., Otsuka, M., Uchibe, E., and Doya, K. (2010). Free-energy based reinforcement learning for vision-based navigation with high-dimensional sensory inputs. In Neural Information Process- ing. Theory and Algorithms (ICONIP), volume 1, pages 215–222. Springer. Eliasmith, C. (2013). How to build a brain: A neural architecture for biological cognition. Oxford University Press, New York, NY. Eliasmith, C., Stewart, T. C., Choo, X., Bekolay, T., DeWolf, T., Tang, Y., and Rasmussen, D. (2012). A large-scale model of the functioning brain. Science, 338(6111):1202–1205. Elman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2):179–211. Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., and Bengio, S. (2010). Why does unsu...",
      "page_number": 46,
      "importance_rank": 3,
      "relevance_score": 1.0,
      "original_length": 4986,
      "refined_length": 1003,
      "domain": "academic"
    },
    {
      "document": "1B",
      "section_title": "Psychologicalreview",
      "refined_text": "Roggen, D., Hofmann, S., Thoma, Y., and Floreano, D. (2003). Hardware spiking neural network with run-time reconﬁgurable connectivity in an autonomous robot. In Proc. NASA/DoD Conference on Evolvable Hardware, 2003, pages 189–198. IEEE. Rohwer, R. (1989). The ‘moving targets’ training method. In Kindermann, J. and Linden, A., edi- tors, Proceedings of ‘Distributed Adaptive Neural Information Processing’, St.Augustin, 24.-25.5,. Oldenbourg. Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6):386. Rosenblatt, F. (1962). Principles of Neurodynamics. Spartan, New York. Roux, L., Racoceanu, D., Lomenie, N., Kulikova, M., Irshad, H., Klossa, J., Capron, F., Genestie, C., Naour, G. L., and Gurcan, M. N. (2013). Mitosis detection in breast cancer histological images - an ICPR 2012 contest. J. Pathol. Inform., 4:8. Rubner, J. and Schulten, K. (1990). Development of feature detectors by self-organization:...",
      "page_number": 74,
      "importance_rank": 4,
      "relevance_score": 1.0,
      "original_length": 2684,
      "refined_length": 1003,
      "domain": "academic"
    },
    {
      "document": "1B",
      "section_title": "5.12 1994:EarlyContest-WinningNNs",
      "refined_text": "greatly reduce problem depth. Compare earlier BP-based ﬁne-tuning of NNs initialized by rules of propositional logic (Shavlik and Towell, 1989) (Sec. 5.6.1). There is a way of compressing higher levels down into lower levels, thus fully or partially col- lapsing the RNN stack. The trick is to retrain a lower-level RNN to continually imitate (predict) the hidden units of an already trained, slower, higher-level RNN (the “conscious” chunker), through ad- ditional predictive output neurons (Schmidhuber, 1992b). This helps the lower RNN (the automatizer) to develop appropriate, rarely changing memories that may bridge very long time lags. Again, this procedure can greatly reduce the required depth of the BP process. The 1991 system was a working Deep Learner in the modern post-2000 sense, and also a ﬁrst Neural Hierarchical Temporal Memory (HTM). It is conceptually similar to earlier AE hierarchies (1987, Sec. 5.7) and later Deep Belief Networks (2006, Sec. 5.15), but more general in the s...",
      "page_number": 18,
      "importance_rank": 5,
      "relevance_score": 0.99,
      "original_length": 28312,
      "refined_length": 1003,
      "domain": "academic"
    }
  ],
  "processing_summary": {
    "sections_analyzed": 5,
    "documents_processed": 1,
    "processing_time_seconds": 6.21
  }
}